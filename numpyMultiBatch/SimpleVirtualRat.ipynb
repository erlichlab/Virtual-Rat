{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Virtual Rat RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cPickle\n",
    "from RNN import SimpleRNN\n",
    "from SimRat import SimRat\n",
    "\n",
    "from RNNfunctions import *\n",
    "from dataProcessFunctions import *\n",
    "from RNN_solver import RNNsolver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "ratFile = open(\"allRatData.pkl\",\"rb\")\n",
    "allRatData = cPickle.load(ratFile)\n",
    "ratFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 1\n",
    "rats = preProcess(allRatData,N,ratnames=['Z009'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RNNs = {}\n",
    "solvers = {}\n",
    "probabilities = {}\n",
    "logical_accuracies = {}\n",
    "real_accuracies = {}\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "\n",
    "# To find the best config\n",
    "min_bias = 10\n",
    "best_length= 0\n",
    "best_init_params = None\n",
    "\n",
    "repeat = 1\n",
    "####### Note the key of the dictionaries!\n",
    "for ratname, rat in rats.iteritems():\n",
    "    print ratname\n",
    "    for length in xrange(10,11):\n",
    "        for i in xrange(repeat):\n",
    "            print \"Batch length is %d\" % (length,)\n",
    "            print \"Training for %d / %d\" % (i+1,repeat)\n",
    "            RNN = SimpleRNN(N = N)\n",
    "            RNNs[i] = RNN\n",
    "            solver = RNNsolver(RNN, rat.trainX, rat.trainY,\n",
    "                               update_rule='adam',\n",
    "                               optim_config={'learning_rate': learning_rate,\n",
    "                           }, num_epochs = 100,\n",
    "                               lr_decay = 1,\n",
    "                               batch_length = length,\n",
    "                               verbose = True)\n",
    "            solvers[i] = solver\n",
    "            solver.train()\n",
    "            choices, probs = rat.predict(RNN)\n",
    "            probabilities[i] = probs\n",
    "\n",
    "            ##############\n",
    "            sample_probabilities(probs, ratname, sample = 50)\n",
    "\n",
    "            ##############\n",
    "            loss_history(solver, ratname)\n",
    "\n",
    "            #############\n",
    "            sample_correct_rate(rat, sample = 500)\n",
    "\n",
    "            # Plot for normalization\n",
    "            trial_window = 3\n",
    "\n",
    "            real_p2a, real_a2p = realRatSwitchCost(rats,trial_window = trial_window)\n",
    "            p2a, a2p = meanPerformance(rats, trial_window = trial_window)\n",
    "    \n",
    "            bias_p2a = bias(real_p2a, p2a)\n",
    "            bias_a2p = bias(real_a2p, a2p)\n",
    "            bias_mean = np.mean([bias_p2a,bias_a2p])\n",
    "            \n",
    "            rp2a = corr(real_p2a, p2a)\n",
    "            ra2p = corr(real_a2p, a2p)\n",
    "            r_mean = np.mean([rp2a,ra2p])\n",
    "            \n",
    "            if bias_mean < min_bias:\n",
    "                min_bias = bias_mean\n",
    "                best_r = r_mean\n",
    "                best_length = length\n",
    "                best_init_params = RNN.initparams\n",
    "            elif bias_mean == min_bias and r_mean > best_r:\n",
    "                min_bias = bias_mean\n",
    "                best_r = r_mean\n",
    "                best_length = length\n",
    "                best_init_params = RNN.initparams\n",
    "                \n",
    "            \n",
    "            print \"The sum of square bias between the model and real rat's data on pro to anti is %f\" % (bias_p2a,)\n",
    "            print \"The sum of square bias between the model and real rat's data on anti to pro is %f\" % (bias_a2p,)\n",
    "            print \"The mean of two sum of square bias is %f\" % (bias_mean,)\n",
    "         \n",
    "            print \"The correlation coefficient between the model and real rat's data on pro to anti is %f\" % (rp2a,)\n",
    "            print \"The correlation coefficient between the model and real rat's data on anti to pro is %f\" % (ra2p,)\n",
    "            print \"The mean correlation coefficients is %f\" % (r_mean,)\n",
    "\n",
    "            draw_3d(real_p2a, real_a2p, p2a, a2p, trial_window = 3)\n",
    "\n",
    "    print \"The minimum bias is %f\" % (min_bias,)\n",
    "    print \"The best correlation coefficient is %f\" % (best_r,)\n",
    "    print \"The best batch length is %d\" % (best_length,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
