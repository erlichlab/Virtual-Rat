{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The very first Virtual Rat RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQLdb not found\n",
      "Using mysql.connector\n",
      "Loaded defaults from ~/.dbconf\n",
      "Z009 (12771, 6)\n",
      "A099 (23265, 6)\n",
      "A109 (42333, 6)\n",
      "Z014 (37888, 6)\n",
      "Z010 (55682, 6)\n",
      "A110 (27157, 6)\n",
      "A112 (15870, 6)\n",
      "A111 (56784, 6)\n",
      "Z006 (40734, 6)\n",
      "A117 (20919, 6)\n",
      "A119 (29117, 6)\n",
      "A121 (29079, 6)\n",
      "A120 (18619, 6)\n",
      "A106 (92159, 6)\n",
      "A098 (68163, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from RNN import FirstRNN\n",
    "from VirtualRatFunctions import *\n",
    "from RNN_solver import RNNsolver\n",
    "# auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "allRatsData = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rat = allRatsData[\"Z009\"]\n",
    "\n",
    "x = np.zeros((1, rat.shape[0], 3))\n",
    "y = np.zeros((1, rat.shape[0]))\n",
    "trueY = np.zeros((1, rat.shape[0]))\n",
    "\n",
    "x[0,:,:] = rat[:,:3]\n",
    "\n",
    "train_num = int(rat.shape[0] * 0.8)\n",
    "val_num = int(rat.shape[0] * 0.9)\n",
    "\n",
    "trainX = x[:,:train_num,:]\n",
    "valX = x[:,train_num:val_num,:]\n",
    "testX = x[:,val_num:,:]\n",
    "\n",
    "y[0,rat[:,3]>0] = 0\n",
    "y[0,rat[:,4]>0] = 1\n",
    "y[0,rat[:,5]>0] = 2\n",
    "\n",
    "trainY = y[:,:train_num]\n",
    "valY = y[:,train_num:val_num]\n",
    "testY = y[:,val_num:]\n",
    "\n",
    "trueY[0,:] = np.logical_not(np.bitwise_xor(rat[:,0],rat[:,1]))\n",
    "trainTrueY = trueY[:,:train_num]\n",
    "valTrueY = trueY[:,train_num:val_num]\n",
    "testTrueY = trueY[:,val_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638 639 0\n",
      "667 610 0\n",
      "[[ 1.         -0.07912846]\n",
      " [-0.07912846  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print np.sum(valTrueY==0), np.sum(valTrueY==1), np.sum(valTrueY==2)\n",
    "print np.sum(out==0), np.sum(out==1), np.sum(out==2)\n",
    "print np.corrcoef(valY, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 200) loss: 11514.403417\n",
      "(Iteration 11 / 200) loss: 7461.996465\n",
      "(Iteration 21 / 200) loss: 6895.439035\n",
      "(Iteration 31 / 200) loss: 6449.462799\n",
      "(Iteration 41 / 200) loss: 6079.562270\n",
      "(Iteration 51 / 200) loss: 5763.690341\n",
      "(Iteration 61 / 200) loss: 5456.233142\n",
      "(Iteration 71 / 200) loss: 5081.872596\n",
      "(Iteration 81 / 200) loss: 4195.309217\n",
      "(Iteration 91 / 200) loss: 2322.417887\n",
      "(Iteration 101 / 200) loss: 1216.350234\n",
      "(Iteration 111 / 200) loss: 816.455215\n",
      "(Iteration 121 / 200) loss: 613.365678\n",
      "(Iteration 131 / 200) loss: 490.116195\n",
      "(Iteration 141 / 200) loss: 407.258387\n",
      "(Iteration 151 / 200) loss: 347.779952\n",
      "(Iteration 161 / 200) loss: 303.070023\n",
      "(Iteration 171 / 200) loss: 268.282364\n",
      "(Iteration 181 / 200) loss: 240.476647\n",
      "(Iteration 191 / 200) loss: 217.765003\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "RNN = FirstRNN(hidden_dim = 2)\n",
    "solver = RNNsolver(RNN, trainX, trainTrueY,optim_config={\n",
    "                 'learning_rate': 8e-5,\n",
    "               }, num_epochs = 200,\n",
    "                   verbose = True)\n",
    "solver.train()\n",
    "out = RNN.predict(valX)\n",
    "acc = np.mean(out == valTrueY)\n",
    "print acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b [-1.61962402 -1.05825377]\n",
      "b_vocab [ 3.40692353 -0.89586729 -2.51105785]\n",
      "h0 [[ 0.00035516  0.00085488]]\n",
      "W_vocab [[ 1.53145134 -3.34091663  0.38654137]\n",
      " [ 2.56627727 -2.37488461  0.90820515]]\n",
      "Wh [[ 0.1030069  -0.08620285]\n",
      " [-0.18873303  0.20145527]]\n",
      "Wx [[-2.92188621  2.44315553]\n",
      " [ 3.00621796 -2.80841804]\n",
      " [-0.78998059 -0.5990895 ]]\n"
     ]
    }
   ],
   "source": [
    "for k, v in RNN.params.iteritems():\n",
    "    print k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded defaults from ~/.dbconf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helpers.DBUtilsClass as db\n",
    "import cPickle as pkl\n",
    "\n",
    "dbc = db.Connection()\n",
    "D = {}\n",
    "D['ratname'] = 'Rtnl'\n",
    "D['train_size'] = train_num\n",
    "D['test_size'] = val_num - train_num\n",
    "\n",
    "D['loss'] = 217.765003\n",
    "D['learning_rate'] = 8e-5\n",
    "D['hidden_dim'] = 2\n",
    "D['accuracy'] = 1.0\n",
    "D['comments'] = \"The well performing RNN with the smallest size ever.\"\n",
    "D['b'] = pkl.dumps(RNN.params['b'])\n",
    "D['b_vocab'] = pkl.dumps(RNN.params['b_vocab'])\n",
    "D['W_vocab'] = pkl.dumps(RNN.params['W_vocab'])\n",
    "D['h0'] = pkl.dumps(RNN.params['h0'])\n",
    "D['Wh'] = pkl.dumps(RNN.params['Wh'])\n",
    "D['Wx'] = pkl.dumps(RNN.params['Wx'])\n",
    "\n",
    "dbc.saveToDB('vrat.rnn',D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.000482546859735, accuracy = 0.495693\n",
      "Best RNN so far: learning rate: 0.000482546859735, accuracy = 0.495693\n",
      "learning rate: 0.000710451125549, accuracy = 0.500392\n",
      "Best RNN so far: learning rate: 0.000710451125549, accuracy = 0.500392\n",
      "learning rate: 0.000152714074241, accuracy = 0.660924\n",
      "Best RNN so far: learning rate: 0.000152714074241, accuracy = 0.660924\n",
      "learning rate: 0.000134399589891, accuracy = 0.742365\n",
      "Best RNN so far: learning rate: 0.000134399589891, accuracy = 0.742365\n",
      "learning rate: 0.000457100045655, accuracy = 0.618637\n",
      "learning rate: 0.000559865787274, accuracy = 0.495693\n",
      "learning rate: 0.0009430690382, accuracy = 0.500392\n",
      "learning rate: 0.000650431005996, accuracy = 0.499608\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8a5adad2aef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                  \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                }, verbose = False)\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalTrueY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lixiangci/Google 云端硬盘/GitHub_codes/VirtualRat/RNN_solver.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Maybe print training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lixiangci/Google 云端硬盘/GitHub_codes/VirtualRat/RNN_solver.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Compute loss and gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lixiangci/Google 云端硬盘/GitHub_codes/VirtualRat/RNN.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemporal_affine_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lixiangci/Google 云端硬盘/GitHub_codes/VirtualRat/VirtualRatFunctions.py\u001b[0m in \u001b[0;36mrnn_forward\u001b[0;34m(x, h0, Wx, Wh, b)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_step_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mprev_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lixiangci/Google 云端硬盘/GitHub_codes/VirtualRat/VirtualRatFunctions.py\u001b[0m in \u001b[0;36mrnn_step_forward\u001b[0;34m(x, prev_h, Wx, Wh, b)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxWx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhWh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mnext_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;31m##############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m#                               END OF YOUR CODE                             #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lrs = np.random.uniform(1,100,20) * 1e-5\n",
    "bestAcc = 0\n",
    "bestRNN = None\n",
    "bestLR = 0\n",
    "for lr in lrs:\n",
    "    RNN = FirstRNN(hidden_dim = 2)\n",
    "    solver = RNNsolver(RNN, trainX, trainTrueY,optim_config={\n",
    "                 'learning_rate': lr,\n",
    "               }, verbose = False)\n",
    "    solver.train()\n",
    "    out = RNN.predict(valX)\n",
    "    acc = np.mean(out == valTrueY)\n",
    "    print \"learning rate: %s, accuracy = %f\" % (lr,acc)\n",
    "    if acc > bestAcc:\n",
    "        bestAcc = acc\n",
    "        bestRNN = RNN\n",
    "        bestLR = lr\n",
    "        print \"Best RNN so far: learning rate: %s, accuracy = %f\" % (lr,acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
